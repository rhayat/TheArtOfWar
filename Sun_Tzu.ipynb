{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "luuLFSg9vuF_"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "import random\n",
        "import keras\n",
        "import keras.backend as K\n",
        "\n",
        "# Load your text file\n",
        "filename = 'artofwar.txt'\n",
        "with open(filename, encoding=\"utf8\") as f:\n",
        "    text = f.read().lower()\n",
        "\n",
        "# Tokenization (at word level)\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([text])\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "# Convert text data into sequence of tokens\n",
        "input_sequences = []\n",
        "for line in text.split('.'):  # Assuming sentences end with a period\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(token_list)):\n",
        "        n_gram_sequence = token_list[:i+1]\n",
        "        input_sequences.append(n_gram_sequence)\n",
        "\n",
        "# Pad sequences for equal length\n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "# Predictors and label\n",
        "predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "label = keras.utils.to_categorical(label, num_classes=total_words)\n",
        "\n",
        "def perplexity(y_true, y_pred):\n",
        "    cross_entropy = K.categorical_crossentropy(y_true, y_pred)\n",
        "    perplexity = K.exp(cross_entropy)\n",
        "    return perplexity"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Embedding(total_words, 100, input_length=max_sequence_len - 1)) #100-dimensional word vectors\n",
        "model.add(keras.layers.Bidirectional(keras.layers.LSTM(150, return_sequences=True))) # Can stack LSTMs if you want deeper understanding\n",
        "model.add(keras.layers.Dropout(0.2))\n",
        "model.add(keras.layers.Bidirectional(keras.layers.LSTM(100)))\n",
        "model.add(keras.layers.Dense(total_words, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy', perplexity])"
      ],
      "metadata": {
        "id": "mKlL8hdLv6V_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(predictors, label, batch_size=64, epochs=200, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDKSbpuev95I",
        "outputId": "b00b92f4-0210-4d53-e3d9-b7d66cc2b2b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "158/158 [==============================] - 27s 112ms/step - loss: 6.5421 - accuracy: 0.0621 - perplexity: 4428.5273\n",
            "Epoch 2/200\n",
            "158/158 [==============================] - 9s 54ms/step - loss: 6.0511 - accuracy: 0.0719 - perplexity: 2959.7747\n",
            "Epoch 3/200\n",
            "158/158 [==============================] - 5s 34ms/step - loss: 5.8368 - accuracy: 0.0962 - perplexity: 2420.8296\n",
            "Epoch 4/200\n",
            "158/158 [==============================] - 5s 30ms/step - loss: 5.6776 - accuracy: 0.1081 - perplexity: 1883.3098\n",
            "Epoch 5/200\n",
            "158/158 [==============================] - 5s 29ms/step - loss: 5.5251 - accuracy: 0.1240 - perplexity: 1503.2175\n",
            "Epoch 6/200\n",
            "158/158 [==============================] - 3s 21ms/step - loss: 5.3811 - accuracy: 0.1347 - perplexity: 1285.1851\n",
            "Epoch 7/200\n",
            "158/158 [==============================] - 4s 26ms/step - loss: 5.2600 - accuracy: 0.1413 - perplexity: 1091.8126\n",
            "Epoch 8/200\n",
            "158/158 [==============================] - 4s 24ms/step - loss: 5.1441 - accuracy: 0.1518 - perplexity: 951.7821\n",
            "Epoch 9/200\n",
            "158/158 [==============================] - 3s 22ms/step - loss: 5.0454 - accuracy: 0.1620 - perplexity: 826.2120\n",
            "Epoch 10/200\n",
            "158/158 [==============================] - 4s 22ms/step - loss: 4.9541 - accuracy: 0.1694 - perplexity: 736.8399\n",
            "Epoch 11/200\n",
            "158/158 [==============================] - 4s 24ms/step - loss: 4.8637 - accuracy: 0.1748 - perplexity: 661.5797\n",
            "Epoch 12/200\n",
            "158/158 [==============================] - 4s 27ms/step - loss: 4.7805 - accuracy: 0.1808 - perplexity: 587.6185\n",
            "Epoch 13/200\n",
            "158/158 [==============================] - 5s 32ms/step - loss: 4.7016 - accuracy: 0.1868 - perplexity: 532.7031\n",
            "Epoch 14/200\n",
            "158/158 [==============================] - 4s 23ms/step - loss: 4.6263 - accuracy: 0.1892 - perplexity: 480.8865\n",
            "Epoch 15/200\n",
            "158/158 [==============================] - 4s 25ms/step - loss: 4.5579 - accuracy: 0.1932 - perplexity: 448.3844\n",
            "Epoch 16/200\n",
            "158/158 [==============================] - 4s 25ms/step - loss: 4.4913 - accuracy: 0.1976 - perplexity: 405.1642\n",
            "Epoch 17/200\n",
            "158/158 [==============================] - 4s 25ms/step - loss: 4.4206 - accuracy: 0.2011 - perplexity: 376.4579\n",
            "Epoch 18/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 4.3604 - accuracy: 0.2059 - perplexity: 351.1978\n",
            "Epoch 19/200\n",
            "158/158 [==============================] - 3s 19ms/step - loss: 4.2913 - accuracy: 0.2092 - perplexity: 324.2042\n",
            "Epoch 20/200\n",
            "158/158 [==============================] - 4s 26ms/step - loss: 4.2291 - accuracy: 0.2111 - perplexity: 304.4317\n",
            "Epoch 21/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 4.1622 - accuracy: 0.2182 - perplexity: 283.5998\n",
            "Epoch 22/200\n",
            "158/158 [==============================] - 4s 23ms/step - loss: 4.0971 - accuracy: 0.2215 - perplexity: 261.0634\n",
            "Epoch 23/200\n",
            "158/158 [==============================] - 4s 27ms/step - loss: 4.0363 - accuracy: 0.2292 - perplexity: 245.4425\n",
            "Epoch 24/200\n",
            "158/158 [==============================] - 3s 21ms/step - loss: 3.9621 - accuracy: 0.2322 - perplexity: 221.3981\n",
            "Epoch 25/200\n",
            "158/158 [==============================] - 3s 21ms/step - loss: 3.9014 - accuracy: 0.2399 - perplexity: 213.5495\n",
            "Epoch 26/200\n",
            "158/158 [==============================] - 4s 24ms/step - loss: 3.8464 - accuracy: 0.2439 - perplexity: 200.2468\n",
            "Epoch 27/200\n",
            "158/158 [==============================] - 4s 23ms/step - loss: 3.7921 - accuracy: 0.2463 - perplexity: 188.7927\n",
            "Epoch 28/200\n",
            "158/158 [==============================] - 4s 22ms/step - loss: 3.7593 - accuracy: 0.2535 - perplexity: 190.7057\n",
            "Epoch 29/200\n",
            "158/158 [==============================] - 3s 22ms/step - loss: 3.6851 - accuracy: 0.2576 - perplexity: 171.1670\n",
            "Epoch 30/200\n",
            "158/158 [==============================] - 4s 25ms/step - loss: 3.6281 - accuracy: 0.2645 - perplexity: 161.7734\n",
            "Epoch 31/200\n",
            "158/158 [==============================] - 3s 22ms/step - loss: 3.5670 - accuracy: 0.2694 - perplexity: 152.2467\n",
            "Epoch 32/200\n",
            "158/158 [==============================] - 3s 21ms/step - loss: 3.5071 - accuracy: 0.2752 - perplexity: 145.4565\n",
            "Epoch 33/200\n",
            "158/158 [==============================] - 4s 23ms/step - loss: 3.4610 - accuracy: 0.2796 - perplexity: 144.2920\n",
            "Epoch 34/200\n",
            "158/158 [==============================] - 3s 22ms/step - loss: 3.3910 - accuracy: 0.2906 - perplexity: 130.5128\n",
            "Epoch 35/200\n",
            "158/158 [==============================] - 3s 21ms/step - loss: 3.3314 - accuracy: 0.2920 - perplexity: 124.7884\n",
            "Epoch 36/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 3.2851 - accuracy: 0.3031 - perplexity: 120.0056\n",
            "Epoch 37/200\n",
            "158/158 [==============================] - 4s 26ms/step - loss: 3.2343 - accuracy: 0.3085 - perplexity: 115.3284\n",
            "Epoch 38/200\n",
            "158/158 [==============================] - 3s 19ms/step - loss: 3.2010 - accuracy: 0.3156 - perplexity: 119.2599\n",
            "Epoch 39/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 3.1341 - accuracy: 0.3206 - perplexity: 106.5349\n",
            "Epoch 40/200\n",
            "158/158 [==============================] - 4s 23ms/step - loss: 3.0743 - accuracy: 0.3327 - perplexity: 102.6461\n",
            "Epoch 41/200\n",
            "158/158 [==============================] - 3s 21ms/step - loss: 3.0161 - accuracy: 0.3388 - perplexity: 101.5501\n",
            "Epoch 42/200\n",
            "158/158 [==============================] - 3s 22ms/step - loss: 2.9610 - accuracy: 0.3493 - perplexity: 92.9791\n",
            "Epoch 43/200\n",
            "158/158 [==============================] - 3s 21ms/step - loss: 2.9180 - accuracy: 0.3563 - perplexity: 91.9139\n",
            "Epoch 44/200\n",
            "158/158 [==============================] - 4s 25ms/step - loss: 2.8690 - accuracy: 0.3609 - perplexity: 86.6447\n",
            "Epoch 45/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 2.8256 - accuracy: 0.3717 - perplexity: 83.4946\n",
            "Epoch 46/200\n",
            "158/158 [==============================] - 3s 21ms/step - loss: 2.7955 - accuracy: 0.3761 - perplexity: 82.0606\n",
            "Epoch 47/200\n",
            "158/158 [==============================] - 4s 22ms/step - loss: 2.7439 - accuracy: 0.3836 - perplexity: 76.5917\n",
            "Epoch 48/200\n",
            "158/158 [==============================] - 3s 22ms/step - loss: 2.6903 - accuracy: 0.3996 - perplexity: 75.3998\n",
            "Epoch 49/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 2.6525 - accuracy: 0.4026 - perplexity: 72.9118\n",
            "Epoch 50/200\n",
            "158/158 [==============================] - 3s 21ms/step - loss: 2.6117 - accuracy: 0.4103 - perplexity: 72.9011\n",
            "Epoch 51/200\n",
            "158/158 [==============================] - 4s 23ms/step - loss: 2.5727 - accuracy: 0.4147 - perplexity: 68.6103\n",
            "Epoch 52/200\n",
            "158/158 [==============================] - 3s 19ms/step - loss: 2.5283 - accuracy: 0.4261 - perplexity: 64.7497\n",
            "Epoch 53/200\n",
            "158/158 [==============================] - 3s 22ms/step - loss: 2.4852 - accuracy: 0.4299 - perplexity: 63.3933\n",
            "Epoch 54/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 2.4894 - accuracy: 0.4306 - perplexity: 65.8026\n",
            "Epoch 55/200\n",
            "158/158 [==============================] - 4s 23ms/step - loss: 2.4144 - accuracy: 0.4486 - perplexity: 58.6366\n",
            "Epoch 56/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 2.3743 - accuracy: 0.4517 - perplexity: 58.6384\n",
            "Epoch 57/200\n",
            "158/158 [==============================] - 3s 21ms/step - loss: 2.3456 - accuracy: 0.4584 - perplexity: 57.5390\n",
            "Epoch 58/200\n",
            "158/158 [==============================] - 4s 23ms/step - loss: 2.3012 - accuracy: 0.4669 - perplexity: 53.8487\n",
            "Epoch 59/200\n",
            "158/158 [==============================] - 3s 22ms/step - loss: 2.2595 - accuracy: 0.4802 - perplexity: 55.4213\n",
            "Epoch 60/200\n",
            "158/158 [==============================] - 3s 21ms/step - loss: 2.2259 - accuracy: 0.4869 - perplexity: 50.9813\n",
            "Epoch 61/200\n",
            "158/158 [==============================] - 3s 21ms/step - loss: 2.1889 - accuracy: 0.4943 - perplexity: 49.5087\n",
            "Epoch 62/200\n",
            "158/158 [==============================] - 4s 23ms/step - loss: 2.1496 - accuracy: 0.4979 - perplexity: 46.7965\n",
            "Epoch 63/200\n",
            "158/158 [==============================] - 3s 21ms/step - loss: 2.1095 - accuracy: 0.5103 - perplexity: 51.0494\n",
            "Epoch 64/200\n",
            "158/158 [==============================] - 3s 21ms/step - loss: 2.0878 - accuracy: 0.5140 - perplexity: 45.2514\n",
            "Epoch 65/200\n",
            "158/158 [==============================] - 4s 22ms/step - loss: 2.0605 - accuracy: 0.5214 - perplexity: 43.6356\n",
            "Epoch 66/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 2.0421 - accuracy: 0.5255 - perplexity: 42.1792\n",
            "Epoch 67/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 1.9987 - accuracy: 0.5335 - perplexity: 41.5958\n",
            "Epoch 68/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 1.9714 - accuracy: 0.5398 - perplexity: 38.6339\n",
            "Epoch 69/200\n",
            "158/158 [==============================] - 4s 23ms/step - loss: 1.9387 - accuracy: 0.5472 - perplexity: 41.5179\n",
            "Epoch 70/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 1.9122 - accuracy: 0.5530 - perplexity: 42.4581\n",
            "Epoch 71/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 1.8718 - accuracy: 0.5604 - perplexity: 36.9963\n",
            "Epoch 72/200\n",
            "158/158 [==============================] - 3s 19ms/step - loss: 1.8457 - accuracy: 0.5659 - perplexity: 34.5735\n",
            "Epoch 73/200\n",
            "158/158 [==============================] - 4s 24ms/step - loss: 1.8194 - accuracy: 0.5762 - perplexity: 34.1789\n",
            "Epoch 74/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 1.7936 - accuracy: 0.5764 - perplexity: 33.5275\n",
            "Epoch 75/200\n",
            "158/158 [==============================] - 3s 22ms/step - loss: 1.7502 - accuracy: 0.5907 - perplexity: 31.2381\n",
            "Epoch 76/200\n",
            "158/158 [==============================] - 4s 24ms/step - loss: 1.7261 - accuracy: 0.5956 - perplexity: 34.0075\n",
            "Epoch 77/200\n",
            "158/158 [==============================] - 3s 21ms/step - loss: 1.7001 - accuracy: 0.6053 - perplexity: 30.7041\n",
            "Epoch 78/200\n",
            "158/158 [==============================] - 3s 21ms/step - loss: 1.6696 - accuracy: 0.6048 - perplexity: 29.7054\n",
            "Epoch 79/200\n",
            "158/158 [==============================] - 3s 21ms/step - loss: 1.6333 - accuracy: 0.6153 - perplexity: 26.1638\n",
            "Epoch 80/200\n",
            "158/158 [==============================] - 4s 23ms/step - loss: 1.6139 - accuracy: 0.6194 - perplexity: 36.5351\n",
            "Epoch 81/200\n",
            "158/158 [==============================] - 3s 22ms/step - loss: 1.6077 - accuracy: 0.6174 - perplexity: 25.2728\n",
            "Epoch 82/200\n",
            "158/158 [==============================] - 3s 21ms/step - loss: 1.5697 - accuracy: 0.6280 - perplexity: 24.4558\n",
            "Epoch 83/200\n",
            "158/158 [==============================] - 4s 25ms/step - loss: 1.5626 - accuracy: 0.6271 - perplexity: 24.0025\n",
            "Epoch 84/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 1.5221 - accuracy: 0.6388 - perplexity: 24.8058\n",
            "Epoch 85/200\n",
            "158/158 [==============================] - 3s 21ms/step - loss: 1.5056 - accuracy: 0.6422 - perplexity: 23.0059\n",
            "Epoch 86/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 1.4744 - accuracy: 0.6505 - perplexity: 36.6714\n",
            "Epoch 87/200\n",
            "158/158 [==============================] - 4s 23ms/step - loss: 1.4454 - accuracy: 0.6568 - perplexity: 22.6695\n",
            "Epoch 88/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 1.4173 - accuracy: 0.6662 - perplexity: 23.8727\n",
            "Epoch 89/200\n",
            "158/158 [==============================] - 3s 21ms/step - loss: 1.3941 - accuracy: 0.6697 - perplexity: 20.2642\n",
            "Epoch 90/200\n",
            "158/158 [==============================] - 3s 21ms/step - loss: 1.3690 - accuracy: 0.6795 - perplexity: 20.2957\n",
            "Epoch 91/200\n",
            "158/158 [==============================] - 4s 24ms/step - loss: 1.3572 - accuracy: 0.6772 - perplexity: 22.8998\n",
            "Epoch 92/200\n",
            "158/158 [==============================] - 3s 19ms/step - loss: 1.3461 - accuracy: 0.6830 - perplexity: 21.1541\n",
            "Epoch 93/200\n",
            "158/158 [==============================] - 3s 21ms/step - loss: 1.3310 - accuracy: 0.6818 - perplexity: 20.5076\n",
            "Epoch 94/200\n",
            "158/158 [==============================] - 4s 23ms/step - loss: 1.2988 - accuracy: 0.6902 - perplexity: 17.7402\n",
            "Epoch 95/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 1.3988 - accuracy: 0.6584 - perplexity: 101.3857\n",
            "Epoch 96/200\n",
            "158/158 [==============================] - 3s 21ms/step - loss: 1.3585 - accuracy: 0.6730 - perplexity: 24.2052\n",
            "Epoch 97/200\n",
            "158/158 [==============================] - 3s 21ms/step - loss: 1.2808 - accuracy: 0.6953 - perplexity: 18.6349\n",
            "Epoch 98/200\n",
            "158/158 [==============================] - 4s 25ms/step - loss: 1.2355 - accuracy: 0.7077 - perplexity: 17.8376\n",
            "Epoch 99/200\n",
            "158/158 [==============================] - 3s 22ms/step - loss: 1.2046 - accuracy: 0.7144 - perplexity: 15.4525\n",
            "Epoch 100/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 1.1727 - accuracy: 0.7190 - perplexity: 14.8119\n",
            "Epoch 101/200\n",
            "158/158 [==============================] - 4s 22ms/step - loss: 1.1534 - accuracy: 0.7309 - perplexity: 13.6324\n",
            "Epoch 102/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 1.1348 - accuracy: 0.7317 - perplexity: 13.9354\n",
            "Epoch 103/200\n",
            "158/158 [==============================] - 3s 21ms/step - loss: 1.1199 - accuracy: 0.7328 - perplexity: 13.6492\n",
            "Epoch 104/200\n",
            "158/158 [==============================] - 3s 22ms/step - loss: 1.0986 - accuracy: 0.7431 - perplexity: 16.2993\n",
            "Epoch 105/200\n",
            "158/158 [==============================] - 4s 24ms/step - loss: 1.0961 - accuracy: 0.7398 - perplexity: 13.4809\n",
            "Epoch 106/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 1.1024 - accuracy: 0.7367 - perplexity: 14.3501\n",
            "Epoch 107/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 1.0619 - accuracy: 0.7489 - perplexity: 12.5578\n",
            "Epoch 108/200\n",
            "158/158 [==============================] - 3s 21ms/step - loss: 1.0526 - accuracy: 0.7485 - perplexity: 11.5781\n",
            "Epoch 109/200\n",
            "158/158 [==============================] - 4s 23ms/step - loss: 1.0251 - accuracy: 0.7573 - perplexity: 12.3257\n",
            "Epoch 110/200\n",
            "158/158 [==============================] - 3s 19ms/step - loss: 1.0248 - accuracy: 0.7604 - perplexity: 13.0687\n",
            "Epoch 111/200\n",
            "158/158 [==============================] - 3s 19ms/step - loss: 0.9903 - accuracy: 0.7690 - perplexity: 12.2580\n",
            "Epoch 112/200\n",
            "158/158 [==============================] - 4s 24ms/step - loss: 0.9773 - accuracy: 0.7672 - perplexity: 11.4877\n",
            "Epoch 113/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 0.9544 - accuracy: 0.7732 - perplexity: 9.6658\n",
            "Epoch 114/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 0.9406 - accuracy: 0.7746 - perplexity: 13.9106\n",
            "Epoch 115/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 0.9353 - accuracy: 0.7787 - perplexity: 9.9217\n",
            "Epoch 116/200\n",
            "158/158 [==============================] - 4s 23ms/step - loss: 0.9108 - accuracy: 0.7852 - perplexity: 9.9199\n",
            "Epoch 117/200\n",
            "158/158 [==============================] - 3s 21ms/step - loss: 0.8981 - accuracy: 0.7906 - perplexity: 9.6895\n",
            "Epoch 118/200\n",
            "158/158 [==============================] - 3s 21ms/step - loss: 0.8965 - accuracy: 0.7888 - perplexity: 9.2898\n",
            "Epoch 119/200\n",
            "158/158 [==============================] - 3s 22ms/step - loss: 0.8942 - accuracy: 0.7863 - perplexity: 81.6583\n",
            "Epoch 120/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 0.8841 - accuracy: 0.7878 - perplexity: 9.5889\n",
            "Epoch 121/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 0.8595 - accuracy: 0.7954 - perplexity: 9.5885\n",
            "Epoch 122/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 0.8379 - accuracy: 0.8024 - perplexity: 9.5856\n",
            "Epoch 123/200\n",
            "158/158 [==============================] - 4s 23ms/step - loss: 0.8308 - accuracy: 0.8031 - perplexity: 8.6125\n",
            "Epoch 124/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 0.8170 - accuracy: 0.8057 - perplexity: 8.2672\n",
            "Epoch 125/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 0.8198 - accuracy: 0.8038 - perplexity: 8.4876\n",
            "Epoch 126/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 0.7846 - accuracy: 0.8151 - perplexity: 69.7452\n",
            "Epoch 127/200\n",
            "158/158 [==============================] - 4s 25ms/step - loss: 0.7803 - accuracy: 0.8121 - perplexity: 23.9734\n",
            "Epoch 128/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 0.7786 - accuracy: 0.8153 - perplexity: 7.9951\n",
            "Epoch 129/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 0.7596 - accuracy: 0.8217 - perplexity: 7.3740\n",
            "Epoch 130/200\n",
            "158/158 [==============================] - 3s 22ms/step - loss: 0.7303 - accuracy: 0.8284 - perplexity: 7.7878\n",
            "Epoch 131/200\n",
            "158/158 [==============================] - 4s 23ms/step - loss: 0.7240 - accuracy: 0.8277 - perplexity: 6.6032\n",
            "Epoch 132/200\n",
            "158/158 [==============================] - 3s 21ms/step - loss: 0.7118 - accuracy: 0.8294 - perplexity: 6.4923\n",
            "Epoch 133/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 0.7072 - accuracy: 0.8343 - perplexity: 6.7777\n",
            "Epoch 134/200\n",
            "158/158 [==============================] - 4s 24ms/step - loss: 0.7036 - accuracy: 0.8348 - perplexity: 6.9203\n",
            "Epoch 135/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 0.6953 - accuracy: 0.8326 - perplexity: 11.7440\n",
            "Epoch 136/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 0.6778 - accuracy: 0.8398 - perplexity: 5.9263\n",
            "Epoch 137/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 0.6575 - accuracy: 0.8437 - perplexity: 6.2654\n",
            "Epoch 138/200\n",
            "158/158 [==============================] - 4s 23ms/step - loss: 0.6476 - accuracy: 0.8505 - perplexity: 623.4437\n",
            "Epoch 139/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 0.6541 - accuracy: 0.8437 - perplexity: 9.9314\n",
            "Epoch 140/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 0.6432 - accuracy: 0.8477 - perplexity: 21621.7949\n",
            "Epoch 141/200\n",
            "158/158 [==============================] - 3s 22ms/step - loss: 0.6194 - accuracy: 0.8541 - perplexity: 5.5789\n",
            "Epoch 142/200\n",
            "158/158 [==============================] - 4s 22ms/step - loss: 0.6276 - accuracy: 0.8496 - perplexity: 6.3256\n",
            "Epoch 143/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 0.6085 - accuracy: 0.8541 - perplexity: 5.7605\n",
            "Epoch 144/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 0.6082 - accuracy: 0.8557 - perplexity: 6.2574\n",
            "Epoch 145/200\n",
            "158/158 [==============================] - 4s 24ms/step - loss: 0.6110 - accuracy: 0.8540 - perplexity: 5.1032\n",
            "Epoch 146/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 0.6073 - accuracy: 0.8563 - perplexity: 11.2348\n",
            "Epoch 147/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 0.6094 - accuracy: 0.8506 - perplexity: 5.6718\n",
            "Epoch 148/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 0.5775 - accuracy: 0.8615 - perplexity: 6.3241\n",
            "Epoch 149/200\n",
            "158/158 [==============================] - 4s 24ms/step - loss: 0.5559 - accuracy: 0.8684 - perplexity: 4.7023\n",
            "Epoch 150/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 0.5323 - accuracy: 0.8773 - perplexity: 4.5556\n",
            "Epoch 151/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 0.5351 - accuracy: 0.8733 - perplexity: 8.9410\n",
            "Epoch 152/200\n",
            "158/158 [==============================] - 3s 21ms/step - loss: 0.5272 - accuracy: 0.8770 - perplexity: 7.4160\n",
            "Epoch 153/200\n",
            "158/158 [==============================] - 3s 22ms/step - loss: 0.5165 - accuracy: 0.8786 - perplexity: 8.1205\n",
            "Epoch 154/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 0.5159 - accuracy: 0.8795 - perplexity: 1829.5305\n",
            "Epoch 155/200\n",
            "158/158 [==============================] - 3s 21ms/step - loss: 0.5032 - accuracy: 0.8816 - perplexity: 4.8433\n",
            "Epoch 156/200\n",
            "158/158 [==============================] - 4s 24ms/step - loss: 0.5051 - accuracy: 0.8812 - perplexity: 4.4760\n",
            "Epoch 157/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 0.5008 - accuracy: 0.8789 - perplexity: 3.8313\n",
            "Epoch 158/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 0.5030 - accuracy: 0.8796 - perplexity: 5.8371\n",
            "Epoch 159/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 0.4891 - accuracy: 0.8850 - perplexity: 3.9699\n",
            "Epoch 160/200\n",
            "158/158 [==============================] - 4s 24ms/step - loss: 0.4904 - accuracy: 0.8860 - perplexity: 4.8884\n",
            "Epoch 161/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 0.4801 - accuracy: 0.8879 - perplexity: 3.8739\n",
            "Epoch 162/200\n",
            "158/158 [==============================] - 3s 21ms/step - loss: 0.4633 - accuracy: 0.8886 - perplexity: 3.7175\n",
            "Epoch 163/200\n",
            "158/158 [==============================] - 4s 23ms/step - loss: 0.4603 - accuracy: 0.8927 - perplexity: 3.6562\n",
            "Epoch 164/200\n",
            "158/158 [==============================] - 3s 21ms/step - loss: 0.4498 - accuracy: 0.8920 - perplexity: 3.5530\n",
            "Epoch 165/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 0.4415 - accuracy: 0.8930 - perplexity: 35.8420\n",
            "Epoch 166/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 0.4493 - accuracy: 0.8938 - perplexity: 5.0366\n",
            "Epoch 167/200\n",
            "158/158 [==============================] - 4s 24ms/step - loss: 0.4521 - accuracy: 0.8894 - perplexity: 3.7561\n",
            "Epoch 168/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 0.4617 - accuracy: 0.8881 - perplexity: 30.8631\n",
            "Epoch 169/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 0.4467 - accuracy: 0.8896 - perplexity: 3.5771\n",
            "Epoch 170/200\n",
            "158/158 [==============================] - 3s 19ms/step - loss: 0.4453 - accuracy: 0.8939 - perplexity: 22.2260\n",
            "Epoch 171/200\n",
            "158/158 [==============================] - 4s 23ms/step - loss: 0.4406 - accuracy: 0.8938 - perplexity: 3.6937\n",
            "Epoch 172/200\n",
            "158/158 [==============================] - 3s 21ms/step - loss: 0.4061 - accuracy: 0.9024 - perplexity: 3.2545\n",
            "Epoch 173/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 0.4079 - accuracy: 0.9015 - perplexity: 3.4687\n",
            "Epoch 174/200\n",
            "158/158 [==============================] - 3s 22ms/step - loss: 0.4091 - accuracy: 0.9035 - perplexity: 9.0060\n",
            "Epoch 175/200\n",
            "158/158 [==============================] - 3s 21ms/step - loss: 0.4027 - accuracy: 0.9022 - perplexity: 3.3308\n",
            "Epoch 176/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 0.3860 - accuracy: 0.9061 - perplexity: 3.3834\n",
            "Epoch 177/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 0.3761 - accuracy: 0.9108 - perplexity: 3.5121\n",
            "Epoch 178/200\n",
            "158/158 [==============================] - 4s 23ms/step - loss: 0.4111 - accuracy: 0.9012 - perplexity: 4.5531\n",
            "Epoch 179/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 0.3986 - accuracy: 0.9016 - perplexity: 3.1384\n",
            "Epoch 180/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 0.3754 - accuracy: 0.9120 - perplexity: 3.1344\n",
            "Epoch 181/200\n",
            "158/158 [==============================] - 3s 21ms/step - loss: 0.3774 - accuracy: 0.9065 - perplexity: 4.6421\n",
            "Epoch 182/200\n",
            "158/158 [==============================] - 4s 23ms/step - loss: 0.3569 - accuracy: 0.9137 - perplexity: 2.8170\n",
            "Epoch 183/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 0.3461 - accuracy: 0.9165 - perplexity: 2.7138\n",
            "Epoch 184/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 0.3431 - accuracy: 0.9157 - perplexity: 2.7130\n",
            "Epoch 185/200\n",
            "158/158 [==============================] - 3s 22ms/step - loss: 0.3528 - accuracy: 0.9141 - perplexity: 2.9503\n",
            "Epoch 186/200\n",
            "158/158 [==============================] - 3s 21ms/step - loss: 0.3606 - accuracy: 0.9114 - perplexity: 2.8886\n",
            "Epoch 187/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 0.3498 - accuracy: 0.9117 - perplexity: 4.0145\n",
            "Epoch 188/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 0.3495 - accuracy: 0.9131 - perplexity: 2.8650\n",
            "Epoch 189/200\n",
            "158/158 [==============================] - 4s 24ms/step - loss: 0.3396 - accuracy: 0.9153 - perplexity: 2.7177\n",
            "Epoch 190/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 0.3397 - accuracy: 0.9196 - perplexity: 2.9684\n",
            "Epoch 191/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 0.3389 - accuracy: 0.9156 - perplexity: 3.3772\n",
            "Epoch 192/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 0.3396 - accuracy: 0.9147 - perplexity: 2.8466\n",
            "Epoch 193/200\n",
            "158/158 [==============================] - 4s 23ms/step - loss: 0.3312 - accuracy: 0.9181 - perplexity: 3.4340\n",
            "Epoch 194/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 0.3368 - accuracy: 0.9141 - perplexity: 9.3113\n",
            "Epoch 195/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 0.3588 - accuracy: 0.9085 - perplexity: 191.5173\n",
            "Epoch 196/200\n",
            "158/158 [==============================] - 6s 36ms/step - loss: 0.3387 - accuracy: 0.9137 - perplexity: 3.0251\n",
            "Epoch 197/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 0.4060 - accuracy: 0.8964 - perplexity: 84.7914\n",
            "Epoch 198/200\n",
            "158/158 [==============================] - 3s 20ms/step - loss: 0.3626 - accuracy: 0.9070 - perplexity: 448.6054\n",
            "Epoch 199/200\n",
            "158/158 [==============================] - 3s 21ms/step - loss: 0.3140 - accuracy: 0.9233 - perplexity: 12.4058\n",
            "Epoch 200/200\n",
            "158/158 [==============================] - 4s 22ms/step - loss: 0.3000 - accuracy: 0.9254 - perplexity: 2.9144\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7fe65f7e5fc0>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(seed_text, next_words, model, max_sequence_len, tokenizer):\n",
        "    for _ in range(next_words):\n",
        "        # Convert the current seed text to token sequence\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\n",
        "        # Predict probabilities for each word\n",
        "        probabilities = model.predict(token_list, verbose=0)[0]\n",
        "\n",
        "        # Choose the word with the highest probability as the next word\n",
        "        predicted_index = np.argmax(probabilities)\n",
        "        output_word = \"\"\n",
        "\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == predicted_index:\n",
        "                output_word = word\n",
        "                break\n",
        "\n",
        "        seed_text += \" \" + output_word\n",
        "\n",
        "    return seed_text\n",
        "\n",
        "# Use the function to generate text\n",
        "seed_text = \"Enemy must not be\"\n",
        "next_words = 50  # Number of words you want to generate\n",
        "generated_text = generate_text(seed_text, next_words, model, max_sequence_len, tokenizer)\n",
        "print(generated_text)"
      ],
      "metadata": {
        "id": "hAcAgJzywijx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}